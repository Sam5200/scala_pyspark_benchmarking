group_by(Type, Operation, Language, MachineID, Dataset)
indices = group %>%
dplyr::group_indices()
group$Index = indices
group2 = group # %>% filter(Index < 20)
group2$Index = as.factor(group2$Index)
ggplot(group2, aes(x = Index, y = TimeTaken, fill=Setup)) +
geom_boxplot() +
facet_wrap(~Index, scales = 'free',ncol=4)
group = merged_data %>%
filter(RunID != 1) %>%
group_by(Type, Operation, Language, MachineID, Dataset)
indices = group %>%
dplyr::group_indices()
group$Index = indices
group2 = group # %>% filter(Index < 20)
group2$Index = as.factor(group2$Index)
ggplot(group2, aes(x = Index, y = TimeTaken, fill=Setup)) +
geom_boxplot() +
facet_wrap(~Index, scales = 'free',ncol=4)
group = merged_data %>%
filter(RunID != 1) %>%
group_by(Type, Operation, Language, MachineID, Dataset)
indices = group %>%
dplyr::group_indices()
group$Index = indices
group2 = group # %>% filter(Index < 20)
group2$Index = as.factor(group2$Index)
ggplot(group2, aes(x = Index, y = TimeTaken, fill=Setup)) +
geom_boxplot() +
facet_wrap(~Index, scales = 'free',ncol=4)
group = merged_data %>%
filter(RunID != 1) %>%
group_by(Type, Operation, Language, MachineID, Dataset)
indices = group %>%
dplyr::group_indices() %>%
as.factor()
group$Index = as.factor(indices)
# group2 = group # %>% filter(Index < 20)
# group2$Index = as.factor(group2$Index)
ggplot(group, aes(x = Index, y = TimeTaken, fill=Setup)) +
geom_boxplot() +
facet_wrap(~Index, scales = 'free',ncol=4)
group = merged_data %>%
filter(RunID != 1) %>%
group_by(Type, Operation, Language, MachineID, Dataset)
indices = group %>%
dplyr::group_indices() %>%
as.factor()
group$Index = as.factor(indices)
# group2 = group # %>% filter(Index < 20)
# group2$Index = as.factor(group2$Index)
by_var = "Setup"
ggplot(group, aes_string(x = "Index", y = "TimeTaken", fill=by_var)) +
geom_boxplot() +
facet_wrap(~Index, scales = 'free',ncol=4)
group = merged_data %>%
filter(RunID != 1) %>%
group_by(Type, Operation, Language, MachineID, Dataset)
plot_hist(grouped_data = group, by_var = "Setup")
summarize_results = function(grouped_data){
rv = grouped_data %>%
summarise(n = n()
,Mean_Time = round(mean(TimeTaken),2)
,Std_Dev_Time= round(sd(TimeTaken),2)
,Coeff_Var_Time = round(Mean_Time/Std_Dev_Time,2)
,Mean_Throughput = round(mean(Throughput),2)
,Std_Dev_Throughput= round(sd(Throughput),2)
,Coeff_Var_Throughput = round(Mean_Throughput/Std_Dev_Throughput,2)
)
return(rv)
}
plot_hist = function(grouped_data, by_var){
indices = grouped_data %>%
dplyr::group_indices() %>%
as.factor()
grouped_data$Index = as.factor(indices)
print(ggplot(grouped_data, aes_string(x = "Index", y = "TimeTaken", fill=by_var)) +
geom_boxplot() +
facet_wrap(~Index, scales = 'free',ncol=4))
}
group = merged_data %>%
filter(RunID != 1) %>%
group_by(Type, Operation, Language, MachineID, Dataset)
plot_hist(grouped_data = group, by_var = "Setup")
# indices = group %>%
#   dplyr::group_indices() %>%
#   as.factor()
#
# group$Index = as.factor(indices)
#
# # group2 = group # %>% filter(Index < 20)
# # group2$Index = as.factor(group2$Index)
#
# by_var = "Setup"
#
# ggplot(group, aes_string(x = "Index", y = "TimeTaken", fill=by_var)) +
#   geom_boxplot() +
#   facet_wrap(~Index, scales = 'free',ncol=4)
group = merged_data %>%
filter(RunID != 1) %>%
group_by(Type, Operation, Language, MachineID, Dataset)
group2 = plot_hist(grouped_data = group, by_var = "Setup")
group2
str(group2)
group2[,Index = 39]
group2$Index = 39
group2$Index
group = merged_data %>%
filter(RunID != 1) %>%
group_by(Type, Operation, Language, MachineID, Dataset)
group2 = plot_hist(grouped_data = group, by_var = "Setup")
str(group2)
group2$data[,group2$data$Index = 39]
group2$data[,group2$data$Index == 39]
group2$data[group2$data$Index == 39,]
#Evaluate outliers
DT::datatable(group2$data[group2$data$Index == 39,])
group = merged_data %>%
filter(RunID != 1) %>%
group_by(Type, Operation, Language, MachineID, Setup, Dataset)
result = summarize_results(group)
DT::datatable(result)
group = merged_data %>%
filter(RunID != 1) %>%
group_by(Type, Operation, Language, MachineID, Setup)
group2 = plot_hist(grouped_data = group, by_var = "Dataset")
group = merged_data %>%
filter(RunID != 1) %>%
group_by(Type, Operation, Language, MachineID, Setup)
group2 = plot_hist(grouped_data = group, by_var = "Dataset")
group = merged_data %>%
filter(RunID != 1) %>%
group_by(Type, Operation, Language, MachineID, Setup)
group2 = plot_hist(grouped_data = group, by_var = "Dataset")
group = merged_data %>%
filter(RunID != 1) %>%
group_by(Type, Operation, Language, MachineID, Setup)
group2 = plot_hist(grouped_data = group, by_var = "Dataset")
group = merged_data %>%
filter(RunID != 1) %>%
group_by(Type, Operation, Dataset, MachineID, Setup, Language)
result = summarize_results(group)
DT::datatable(result)
group = merged_data %>%
filter(RunID != 1) %>%
group_by(Type, Operation, Dataset, MachineID, Setup)
group2 = plot_hist(grouped_data = group, by_var = "Language")
group = merged_data %>%
filter(RunID != 1) %>%
group_by(Type, Operation, Language, Dataset, Setup, MachineID)
result = summarize_results(group)
DT::datatable(result)
group = merged_data %>%
filter(RunID != 1) %>%
group_by(Type, Operation, Language, Dataset, Setup)
group2 = plot_hist(grouped_data = group, by_var = "MachineID")
summary(merged_data)
read.clean.files = function(filename){
file = read.csv(filename, header = FALSE)
column.names = c("Language","Randomize","Dataset","MachineID","RunID","Type","Operation","TimeTaken")
colnames(file) = column.names
return(file)
}
files = list.files(path = "../Results/", pattern = ".csv$", recursive = TRUE, full.names = TRUE) # List all .csv files
#files
databricks.files = files[grepl("Databricks",files)]
local.vm..files = files[grepl("Local_VM",files)]
rows.databricks = lapply(databricks.files, read.csv, header = FALSE) # Read the files into list
merged.databricks = do.call(rbind, rows.databricks) # combine the data.frame
merged.databricks$Setup = 'Databricks'
rows.local.vm = lapply(local.vm..files, read.csv, header = FALSE) # Read the files into list
merged.local.vm = do.call(rbind, rows.local.vm) # combine the data.frame
merged.local.vm$Setup = 'Local VM'
merged_data = rbind(merged.databricks,merged.local.vm)
merged_data$Setup = as.factor(merged_data$Setup)
column.names = c("Language","Randomize","Dataset","MachineID","RunID","Type","Operation","TimeTaken","Setup")
colnames(merged_data) = column.names
merged_data$Type = as.factor(gsub(pattern = "Operations", replacement = "Operation", x = merged_data$Type))
merged_data$MachineID = as.factor(merged_data$MachineID)
merged_data$Randomize = as.factor(merged_data$Randomize)
str(merged_data)
head(merged_data)
summary(merged_data)
merged_data = merged_data %>% filter(RunID != 1)
str(merged_data)
summary(merged_data)
read.clean.files = function(filename){
file = read.csv(filename, header = FALSE)
column.names = c("Language","Randomize","Dataset","MachineID","RunID","Type","Operation","TimeTaken")
colnames(file) = column.names
return(file)
}
files = list.files(path = "../Results/", pattern = ".csv$", recursive = TRUE, full.names = TRUE) # List all .csv files
#files
databricks.files = files[grepl("Databricks",files)]
local.vm..files = files[grepl("Local_VM",files)]
rows.databricks = lapply(databricks.files, read.csv, header = FALSE) # Read the files into list
merged.databricks = do.call(rbind, rows.databricks) # combine the data.frame
merged.databricks$Setup = 'Databricks'
rows.local.vm = lapply(local.vm..files, read.csv, header = FALSE) # Read the files into list
merged.local.vm = do.call(rbind, rows.local.vm) # combine the data.frame
merged.local.vm$Setup = 'Local VM'
merged_data = rbind(merged.databricks,merged.local.vm)
merged_data$Setup = as.factor(merged_data$Setup)
column.names = c("Language","Randomize","Dataset","MachineID","RunID","Type","Operation","TimeTaken","Setup")
colnames(merged_data) = column.names
merged_data$Type = as.factor(gsub(pattern = "Operations", replacement = "Operation", x = merged_data$Type))
merged_data = merged_data %>% filter(RunID != 1)
# Convert columns to factors
merged_data$MachineID = as.factor(merged_data$MachineID)
merged_data$Randomize = as.factor(merged_data$Randomize)
merged_data$RunID = as.factor(merged_data$RunID)
str(merged_data)
head(merged_data)
summary(merged_data)
summary(merged_data)
read.clean.files = function(filename){
file = read.csv(filename, header = FALSE)
column.names = c("Language","Randomize","Dataset","MachineID","RunID","Type","Operation","TimeTaken")
colnames(file) = column.names
return(file)
}
files = list.files(path = "../Results/", pattern = ".csv$", recursive = TRUE, full.names = TRUE) # List all .csv files
#files
databricks.files = files[grepl("Databricks",files)]
local.vm..files = files[grepl("Local_VM",files)]
rows.databricks = lapply(databricks.files, read.csv, header = FALSE) # Read the files into list
merged.databricks = do.call(rbind, rows.databricks) # combine the data.frame
merged.databricks$Setup = 'Databricks'
rows.local.vm = lapply(local.vm..files, read.csv, header = FALSE) # Read the files into list
merged.local.vm = do.call(rbind, rows.local.vm) # combine the data.frame
merged.local.vm$Setup = 'Local VM'
merged_data = rbind(merged.databricks,merged.local.vm)
merged_data$Setup = as.factor(merged_data$Setup)
column.names = c("Language","Randomize","Dataset","MachineID","RunID","Type","Operation","TimeTaken","Setup")
colnames(merged_data) = column.names
merged_data$Type = as.factor(gsub(pattern = "Operations", replacement = "Operation", x = merged_data$Type))
#merged_data = merged_data %>% filter(RunID != 1)
# Convert columns to factors
merged_data$MachineID = as.factor(merged_data$MachineID)
merged_data$Randomize = as.factor(merged_data$Randomize)
merged_data$RunID = as.factor(merged_data$RunID)
merged_data$Dat
str(merged_data)
head(merged_data)
summary(merged_data)
read.clean.files = function(filename){
file = read.csv(filename, header = FALSE)
column.names = c("Language","Randomize","Dataset","MachineID","RunID","Type","Operation","TimeTaken")
colnames(file) = column.names
return(file)
}
files = list.files(path = "../Results/", pattern = ".csv$", recursive = TRUE, full.names = TRUE) # List all .csv files
#files
databricks.files = files[grepl("Databricks",files)]
local.vm..files = files[grepl("Local_VM",files)]
rows.databricks = lapply(databricks.files, read.csv, header = FALSE) # Read the files into list
merged.databricks = do.call(rbind, rows.databricks) # combine the data.frame
merged.databricks$Setup = 'Databricks'
rows.local.vm = lapply(local.vm..files, read.csv, header = FALSE) # Read the files into list
merged.local.vm = do.call(rbind, rows.local.vm) # combine the data.frame
merged.local.vm$Setup = 'Local VM'
merged_data = rbind(merged.databricks,merged.local.vm)
merged_data$Setup = as.factor(merged_data$Setup)
column.names = c("Language","Randomize","Dataset","MachineID","RunID","Type","Operation","TimeTaken","Setup")
colnames(merged_data) = column.names
merged_data$Type = as.factor(gsub(pattern = "Operations", replacement = "Operation", x = merged_data$Type))
#merged_data = merged_data %>% filter(RunID != 1)
# Convert columns to factors
merged_data$MachineID = as.factor(merged_data$MachineID)
merged_data$Randomize = as.factor(merged_data$Randomize)
merged_data$RunID = as.factor(merged_data$RunID)
merged_data$Dat
read.clean.files = function(filename){
file = read.csv(filename, header = FALSE)
column.names = c("Language","Randomize","Dataset","MachineID","RunID","Type","Operation","TimeTaken")
colnames(file) = column.names
return(file)
}
files = list.files(path = "../Results/", pattern = ".csv$", recursive = TRUE, full.names = TRUE) # List all .csv files
#files
databricks.files = files[grepl("Databricks",files)]
local.vm..files = files[grepl("Local_VM",files)]
rows.databricks = lapply(databricks.files, read.csv, header = FALSE) # Read the files into list
merged.databricks = do.call(rbind, rows.databricks) # combine the data.frame
merged.databricks$Setup = 'Databricks'
rows.local.vm = lapply(local.vm..files, read.csv, header = FALSE) # Read the files into list
merged.local.vm = do.call(rbind, rows.local.vm) # combine the data.frame
merged.local.vm$Setup = 'Local VM'
merged_data = rbind(merged.databricks,merged.local.vm)
merged_data$Setup = as.factor(merged_data$Setup)
column.names = c("Language","Randomize","Dataset","MachineID","RunID","Type","Operation","TimeTaken","Setup")
colnames(merged_data) = column.names
merged_data$Type = as.factor(gsub(pattern = "Operations", replacement = "Operation", x = merged_data$Type))
#merged_data = merged_data %>% filter(RunID != 1)
# Convert columns to factors
merged_data$MachineID = as.factor(merged_data$MachineID)
merged_data$Randomize = as.factor(merged_data$Randomize)
merged_data$RunID = as.factor(merged_data$RunID)
merged_data$Dataset = factor(merged_data$Dataset, levels = order(merged_data$Dataset))
str(merged_data)
head(merged_data)
summary(merged_data)
summary(merged_data)
order(merged_data$Dataset)
sort(merged_data$Dataset)
sort(unique(merged_data$Dataset))
unique(merged_data$Dataset))
unique(merged_data$Dataset)
read.clean.files = function(filename){
file = read.csv(filename, header = FALSE)
column.names = c("Language","Randomize","Dataset","MachineID","RunID","Type","Operation","TimeTaken")
colnames(file) = column.names
return(file)
}
files = list.files(path = "../Results/", pattern = ".csv$", recursive = TRUE, full.names = TRUE) # List all .csv files
#files
databricks.files = files[grepl("Databricks",files)]
local.vm..files = files[grepl("Local_VM",files)]
rows.databricks = lapply(databricks.files, read.csv, header = FALSE) # Read the files into list
merged.databricks = do.call(rbind, rows.databricks) # combine the data.frame
merged.databricks$Setup = 'Databricks'
rows.local.vm = lapply(local.vm..files, read.csv, header = FALSE) # Read the files into list
merged.local.vm = do.call(rbind, rows.local.vm) # combine the data.frame
merged.local.vm$Setup = 'Local VM'
merged_data = rbind(merged.databricks,merged.local.vm)
merged_data$Setup = as.factor(merged_data$Setup)
column.names = c("Language","Randomize","Dataset","MachineID","RunID","Type","Operation","TimeTaken","Setup")
colnames(merged_data) = column.names
merged_data$Type = as.factor(gsub(pattern = "Operations", replacement = "Operation", x = merged_data$Type))
#merged_data = merged_data %>% filter(RunID != 1)
# Convert columns to factors
merged_data$MachineID = as.factor(merged_data$MachineID)
merged_data$Randomize = as.factor(merged_data$Randomize)
merged_data$RunID = as.factor(merged_data$RunID)
#merged_data$Dataset = factor(merged_data$Dataset, levels = order(merged_data$Dataset))
unique(merged_data$Dataset)
str(merged_data)
head(merged_data)
summary(merged_data)
unique(merged_data$Dataset)
sort(unique(merged_data$Dataset))
grepl("dataset_(*)+MB$",merged_data$Dataset)
grepl("dataset_(.)+MB$",merged_data$Dataset)
sub("dataset_(.)+MB$",".",merged_data$Dataset)
read.clean.files = function(filename){
file = read.csv(filename, header = FALSE)
column.names = c("Language","Randomize","Dataset","MachineID","RunID","Type","Operation","TimeTaken")
colnames(file) = column.names
return(file)
}
files = list.files(path = "../Results/", pattern = ".csv$", recursive = TRUE, full.names = TRUE) # List all .csv files
#files
databricks.files = files[grepl("Databricks",files)]
local.vm..files = files[grepl("Local_VM",files)]
rows.databricks = lapply(databricks.files, read.csv, header = FALSE) # Read the files into list
merged.databricks = do.call(rbind, rows.databricks) # combine the data.frame
merged.databricks$Setup = 'Databricks'
rows.local.vm = lapply(local.vm..files, read.csv, header = FALSE) # Read the files into list
merged.local.vm = do.call(rbind, rows.local.vm) # combine the data.frame
merged.local.vm$Setup = 'Local VM'
merged_data = rbind(merged.databricks,merged.local.vm)
merged_data$Setup = as.factor(merged_data$Setup)
column.names = c("Language","Randomize","Dataset","MachineID","RunID","Type","Operation","TimeTaken","Setup")
colnames(merged_data) = column.names
merged_data$Type = as.factor(gsub(pattern = "Operations", replacement = "Operation", x = merged_data$Type))
#merged_data = merged_data %>% filter(RunID != 1)
# Convert columns to factors
merged_data$MachineID = as.factor(merged_data$MachineID)
merged_data$Randomize = as.factor(merged_data$Randomize)
merged_data$RunID = as.factor(merged_data$RunID)
#merged_data$Dataset = factor(merged_data$Dataset, levels = order(merged_data$Dataset))
sort(unique(merged_data$Dataset))
sub("dataset_(.)+MB$","(.)",merged_data$Dataset)
substr("abcdef", 2, 4)
sub("^dataset_","",merged_data$Dataset)
sub("^dataset_(.)+MB$","",merged_data$Dataset)
sub("^dataset_(.)+MB$",(.),merged_data$Dataset)
sub("^dataset_(.)+MB$", . ,merged_data$Dataset)
sub("^dataset_(.)+MB$",  ,merged_data$Dataset)
sub("^dataset_(.)+MB$", () ,merged_data$Dataset)
sub("^[dataset_].+[MB]$", "" ,merged_data$Dataset)
sub("^[dataset_].*[MB]$", "" ,merged_data$Dataset)
merged_data$Dataset %>% str_replace("^[dataset_]","")
merged_data$Dataset %>% str_replace("^dataset_","")
merged_data$Dataset %>% str_replace("^dataset_(.*)MB$","")
substr(merged_data$Dataset, 8, 2)
sort(unique(merged_data$Dataset))
substr("abcdef", 2, 4)
substr(merged_data$Dataset, 9, 2)
sub("dataset_", merged_data$Dataset)
sub("dataset_", "", merged_data$Dataset)
merged_data$Dataset = sub("MB$", "", merged_data$Dataset)
merged_data$Dataset = sub("dataset_", "", merged_data$Dataset)
merged_data$Dataset = sub("MB$", "", merged_data$Dataset)
merged_data$Dataset
read.clean.files = function(filename){
file = read.csv(filename, header = FALSE)
column.names = c("Language","Randomize","Dataset","MachineID","RunID","Type","Operation","TimeTaken")
colnames(file) = column.names
return(file)
}
files = list.files(path = "../Results/", pattern = ".csv$", recursive = TRUE, full.names = TRUE) # List all .csv files
#files
databricks.files = files[grepl("Databricks",files)]
local.vm..files = files[grepl("Local_VM",files)]
rows.databricks = lapply(databricks.files, read.csv, header = FALSE) # Read the files into list
merged.databricks = do.call(rbind, rows.databricks) # combine the data.frame
merged.databricks$Setup = 'Databricks'
rows.local.vm = lapply(local.vm..files, read.csv, header = FALSE) # Read the files into list
merged.local.vm = do.call(rbind, rows.local.vm) # combine the data.frame
merged.local.vm$Setup = 'Local VM'
merged_data = rbind(merged.databricks,merged.local.vm)
merged_data$Setup = as.factor(merged_data$Setup)
column.names = c("Language","Randomize","Dataset","MachineID","RunID","Type","Operation","TimeTaken","Setup")
colnames(merged_data) = column.names
merged_data$Type = as.factor(gsub(pattern = "Operations", replacement = "Operation", x = merged_data$Type))
merged_data = merged_data %>% filter(RunID != 1)
# Convert columns to factors
merged_data$MachineID = as.factor(merged_data$MachineID)
merged_data$Randomize = as.factor(merged_data$Randomize)
merged_data$RunID = as.factor(merged_data$RunID)
merged_data$Dataset = sub("dataset_", "", merged_data$Dataset)
merged_data$Dataset = sub("MB$", "", merged_data$Dataset)
merged_data$Dataset = as.factor(merged_data$Dataset)
str(merged_data)
head(merged_data)
summary(merged_data)
summary(merged_data)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(DT)
read.clean.files = function(filename){
file = read.csv(filename, header = FALSE)
column.names = c("Language","Randomize","Dataset","MachineID","RunID","Type","Operation","TimeTaken")
colnames(file) = column.names
return(file)
}
files = list.files(path = "../Results/", pattern = ".csv$", recursive = TRUE, full.names = TRUE) # List all .csv files
#files
databricks.files = files[grepl("Databricks",files)]
local.vm..files = files[grepl("Local_VM",files)]
rows.databricks = lapply(databricks.files, read.csv, header = FALSE) # Read the files into list
merged.databricks = do.call(rbind, rows.databricks) # combine the data.frame
merged.databricks$Setup = 'Databricks'
rows.local.vm = lapply(local.vm..files, read.csv, header = FALSE) # Read the files into list
merged.local.vm = do.call(rbind, rows.local.vm) # combine the data.frame
merged.local.vm$Setup = 'Local VM'
merged_data = rbind(merged.databricks,merged.local.vm)
merged_data$Setup = as.factor(merged_data$Setup)
column.names = c("Language","Randomize","Dataset","MachineID","RunID","Type","Operation","TimeTaken","Setup")
colnames(merged_data) = column.names
merged_data$Type = as.factor(gsub(pattern = "Operations", replacement = "Operation", x = merged_data$Type))
merged_data = merged_data %>% filter(RunID != 1)
# Convert columns to factors
merged_data$MachineID = as.factor(merged_data$MachineID)
merged_data$Randomize = as.factor(merged_data$Randomize)
merged_data$RunID = as.factor(merged_data$RunID)
merged_data$Dataset = sub("dataset_", "", merged_data$Dataset)
merged_data$Dataset = sub("MB$", "", merged_data$Dataset)
merged_data$Dataset = as.factor(merged_data$Dataset)
str(merged_data)
head(merged_data)
summary(merged_data)
size_10MB =  11.4789848327637 # file.size("../../Data/Databricks/machine2/dataset_10MB.csv")/(1024*1024)
size_100MB = 115.640992164612 # file.size("../../Data/Databricks/machine2/dataset_100MB.csv")/(1024*1024)
size_200MB = 229.8573
size_300MB = 343.2709
size_500MB = 576.678165435791 # file.size("../../Data/Databricks/machine2/dataset_500MB.csv")/(1024*1024)
print(paste("Actual Size of 10MB file (in MB)",size_10MB))
print(paste("Actual Size of 100MB file (in MB)",size_100MB))
print(paste("Actual Size of 200MB file (in MB)",size_200MB))
print(paste("Actual Size of 300MB file (in MB)",size_300MB))
print(paste("Actual Size of 500MB file (in MB)",size_500MB))
size_info = data.frame(Dataset = c("10","100","200","300","500")
,Size = c(size_10MB,size_100MB,size_200MB,size_300MB,size_500MB))
str(size_info)
merged_data = merged_data %>%
merge(size_info) %>%
mutate(Throughput = Size/TimeTaken)
summarize_results = function(grouped_data){
rv = grouped_data %>%
summarise(n = n()
,Mean_Time = round(mean(TimeTaken),2)
,Std_Dev_Time= round(sd(TimeTaken),2)
,Coeff_Var_Time = round(Mean_Time/Std_Dev_Time,2)
,Mean_Throughput = round(mean(Throughput),2)
,Std_Dev_Throughput= round(sd(Throughput),2)
,Coeff_Var_Throughput = round(Mean_Throughput/Std_Dev_Throughput,2)
)
return(rv)
}
plot_hist = function(grouped_data, by_var){
indices = grouped_data %>%
dplyr::group_indices() %>%
as.factor()
grouped_data$Index = as.factor(indices)
print(ggplot(grouped_data, aes_string(x = "Index", y = "TimeTaken", fill=by_var)) +
geom_boxplot() +
facet_wrap(~Index, scales = 'free',ncol=4))
return(grouped_data)
}
group = merged_data %>%
group_by(Type, Operation, Language, MachineID, Dataset, Setup)
result = summarize_results(group)
DT::datatable(result)
group = merged_data %>%
group_by(Type, Operation, Language, MachineID, Dataset)
group2 = plot_hist(grouped_data = group, by_var = "Setup")
#Evaluate outliers
DT::datatable(group2$data[group2$data$Index == 39,])
