knitr::opts_chunk$set(echo = TRUE)
file1 = read.csv("../Results/Databricks/machine2/PySpark_dataset_10MB_20190323_1900.csv")
file1 = read.csv("../Results/Databricks/machine2/PySpark_dataset_100MB_20190323_1935.csv")
str(file1)
merged_data = merge(file1,file2)
file1 = read.csv("../Results/Databricks/machine2/PySpark_dataset_10MB_20190323_1900.csv")
file2 = read.csv("../Results/Databricks/machine2/PySpark_dataset_100MB_20190323_1935.csv")
merged_data = merge(file1,file2)
str(file1)
str(file1)
str(merged_data)
str(file1)
str(file2)
str(merged_data)
file1 = read.csv("../Results/Databricks/machine2/PySpark_dataset_10MB_20190323_1900.csv")
file2 = read.csv("../Results/Databricks/machine2/PySpark_dataset_100MB_20190323_1935.csv")
merged_data = rbind(file1,file2)
str(file1)
str(file2)
file1 = read.csv("../Results/Databricks/machine2/PySpark_dataset_10MB_20190323_1900.csv")
file2 = read.csv("../Results/Databricks/machine2/PySpark_dataset_100MB_20190323_1935.csv")
column.names = c("Language","Randomize","Dataset","MachineID","RunID","Type","Operation","TimeTaken")
colnames(file1) = column.names
colnames(file2) = column.names
merged_data = rbind(file1,file2)
str(file1)
str(file2)
str(merged_data)
# str(file1)
# str(file2)
# str(merged_data)
file1 = read.csv("../Results/Databricks/machine2/PySpark_dataset_10MB_20190323_1900.csv")
file2 = read.csv("../Results/Databricks/machine2/PySpark_dataset_100MB_20190323_1935.csv")
column.names = c("Language","Randomize","Dataset","MachineID","RunID","Type","Operation","TimeTaken")
colnames(file1) = column.names
colnames(file2) = column.names
merged_data = rbind(file1,file2)
# str(file1)
# str(file2)
# str(merged_data)
summary(merged_data)
file1 = read.csv("../Results/Databricks/machine2/PySpark_dataset_10MB_20190323_1900.csv")
file2 = read.csv("../Results/Databricks/machine2/PySpark_dataset_100MB_20190323_1935.csv")
column.names = c("Language","Randomize","Dataset","MachineID","RunID","Type","Operation","TimeTaken")
colnames(file1) = column.names
colnames(file2) = column.names
merged_data = rbind(file1,file2)
# str(file1)
# str(file2)
# str(merged_data)
summary(merged_data)
library(tidyverse)
merged_data %>% group_by(Language, Dataset)
merged_data %>%
filter(RunID != 1) %>%
group_by(Language, MachineID, Dataset, Type, Operation) %>%
summarise()
merged_data %>%
filter(RunID != 1) %>%
group_by(Language, MachineID, Dataset, Type, Operation) %>%
summarise(n = n())
merged_data %>%
filter(RunID != 1) %>%
group_by(Language, MachineID, Dataset, Type, Operation) %>%
summarise(n = n(), Mean = mean(TimeTaken), Standard Deviation = sd(TimeTaken))
merged_data %>%
filter(RunID != 1) %>%
group_by(Language, MachineID, Dataset, Type, Operation) %>%
summarise(n = n(), Mean = mean(TimeTaken), Std_dev= sd(TimeTaken))
merged_data %>%
filter(RunID != 1) %>%
group_by(Language, MachineID, Dataset, Type, Operation) %>%
summarise(n = n(), Mean = mean(TimeTaken), Std_dev= sd(TimeTaken), Coeff_Var = Mean/Std_dev)
merged_data %>%
filter(RunID != 1) %>%
group_by(Type, Operation, Language, MachineID, Dataset) %>%
summarise(n = n(), Mean = mean(TimeTaken), Std_dev= sd(TimeTaken), Coeff_Var = Mean/Std_dev)
file.size("../Results/Databricks/machine2/PySpark_dataset_10MB_20190323_1900.csv")
file.size("../../Data/Databricks/machine2/dataset_10MB.csv")
file.size("../../Data/Databricks/machine2/dataset_10MB.csv")
file.size("../../Data/Databricks/machine2/dataset_100MB.csv")
file.size("../../Data/Databricks/machine2/dataset_10MB.csv")/1024
file.size("../../Data/Databricks/machine2/dataset_10MB.csv")/(1024*1024)
file.size("../../Data/Databricks/machine2/dataset_100MB.csv")/(1024*1024)
file.size("../../Data/Databricks/machine2/dataset_100MB.csv")/(1024)
file.size("../../Data/Databricks/machine2/dataset_100MB.csv")/(1024*1024)
size_10MB = file.size("../../Data/Databricks/machine2/dataset_10MB.csv")/(1024*1024)
size_100MB = file.size("../../Data/Databricks/machine2/dataset_100MB.csv")/(1024*1024)
merged_data %>%
mutate_if(Dataset == "dataset_10MB", size = size_10MB)
merged_data %>%
mutate_if('Dataset' == "dataset_10MB", size = size_10MB)
_
summary(merged_data)
merged_data %>%
mutate_if(Dataset == "dataset_10MB", size = size_10MB)
merged_data %>%
mutate_if(merged_data$Dataset == "dataset_10MB", size = size_10MB)
size_10MB = file.size("../../Data/Databricks/machine2/dataset_10MB.csv")/(1024*1024)
size_100MB = file.size("../../Data/Databricks/machine2/dataset_100MB.csv")/(1024*1024)
size_info = data.frame(Dataset = c("dataset_10MB","dataset_100MB"), Size = c(size_10MB,size_100MB))
size_10MB = file.size("../../Data/Databricks/machine2/dataset_10MB.csv")/(1024*1024)
size_100MB = file.size("../../Data/Databricks/machine2/dataset_100MB.csv")/(1024*1024)
size_info = data.frame(Dataset = c("dataset_10MB","dataset_100MB"), Size = c(size_10MB,size_100MB))
str(size_info)
merged_data %>%
merge(Dataset)
merged_data %>%
merge(size_info, by = Dataset)
merge(size_info, by = "Dataset"")
merged_data %>%
merge(size_info, by = "Dataset")
merged_data %>%
merge(size_info)
merged_data %>%
merge(size_info) %>%
mutate(Throughput = TimeTaken/Size)
merged_data = merged_data %>%
merge(size_info) %>%
mutate(Throughput = TimeTaken/Size)
merged_data %>%
filter(RunID != 1) %>%
group_by(Type, Operation, Language, MachineID, Dataset) %>%
summarise(n = n()
,Mean_Time = mean(TimeTaken)
,Std_Dev_Time= sd(TimeTaken)
,Coeff_Var_Time = Mean_Time/Std_Dev_Time
,Mean_Throughput = mean(Throughput)
,Std_Dev_Throughput= sd(Throughput)
,Coeff_Var_Throughput = Mean_Throughput/Std_Dev_Throughput
)
library(DT)
result = merged_data %>%
filter(RunID != 1) %>%
group_by(Type, Operation, Language, MachineID, Dataset) %>%
summarise(n = n()
,Mean_Time = mean(TimeTaken)
,Std_Dev_Time= sd(TimeTaken)
,Coeff_Var_Time = Mean_Time/Std_Dev_Time
,Mean_Throughput = mean(Throughput)
,Std_Dev_Throughput= sd(Throughput)
,Coeff_Var_Throughput = Mean_Throughput/Std_Dev_Throughput
)
DT::datatable(result)
