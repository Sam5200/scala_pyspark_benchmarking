{"paragraphs":[{"text":"import org.apache.spark.sql.SparkSession\r\nval spark = SparkSession.builder().getOrCreate()\r\n\r\n// Create a DataFrame from Spark Session read csv\r\n// Technically known as class Dataset\r\n","user":"anonymous","dateUpdated":"2019-03-06T04:12:38+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.SparkSession\nspark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@43414bd4\norg.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ip-172-31-17-108.us-east-2.compute.internal:8020/user/zeppelin/data_rand.csv;\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:558)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:545)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.immutable.List.foreach(List.scala:392)\n  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n  at scala.collection.immutable.List.flatMap(List.scala:355)\n  at org.apache.spark.sql.execution.datasources.DataSource.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:545)\n  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:359)\n  at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n  at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:617)\n  at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:468)\n  ... 52 elided\n"}]},"apps":[],"jobName":"paragraph_1551845482366_2068560438","id":"20190306-041122_1556195828","dateCreated":"2019-03-06T04:11:22+0000","dateStarted":"2019-03-06T04:11:38+0000","dateFinished":"2019-03-06T04:12:10+0000","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6168"},{"text":"\r\nval df = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(\"https://raw.githubusercontent.com/maxmoro/SMU-DB7330-Spark_python/master/data_rand_test.csv\")\r\ndf.head(6)\r\ndf.printSchema()\r\ndf.groupBy(\"group1\",\"group2\").count().orderBy(\"group1\",\"group2\").show()\r\ndf.groupBy(\"group1\",\"group2\").mean(\"int1\",\"float19\").orderBy(\"group1\",\"group2\").show()\r\n","user":"anonymous","dateUpdated":"2019-03-06T04:22:34+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":500,"optionOpen":false}}},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.io.IOException: No FileSystem for scheme: https\n  at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2846)\n  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2857)\n  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)\n  at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)\n  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2878)\n  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:392)\n  at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:547)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:545)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.immutable.List.foreach(List.scala:392)\n  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n  at scala.collection.immutable.List.flatMap(List.scala:355)\n  at org.apache.spark.sql.execution.datasources.DataSource.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:545)\n  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:359)\n  at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n  at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:617)\n  at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:468)\n  ... 52 elided\n"}]},"apps":[],"jobName":"paragraph_1551845498432_-1151951382","id":"20190306-041138_1559894867","dateCreated":"2019-03-06T04:11:38+0000","dateStarted":"2019-03-06T04:22:11+0000","dateFinished":"2019-03-06T04:22:11+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:6169"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1551845575024_-1815329356","id":"20190306-041255_595862518","dateCreated":"2019-03-06T04:12:55+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:6170"}],"name":"scala_data_test","id":"2E7C2PNC4","noteParams":{},"noteForms":{},"angularObjects":{"python:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}